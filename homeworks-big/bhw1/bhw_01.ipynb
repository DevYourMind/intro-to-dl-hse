{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "\n",
    "device = torch_directml.device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "TEST_SIZE = 0.5\n",
    "\n",
    "\n",
    "class BWHDataset(Dataset):\n",
    "    SPLIT_RANDOM_SEED = RANDOM_STATE\n",
    "    SPLIT_TEST_SIZE = TEST_SIZE\n",
    "\n",
    "    def __init__(self, folder, train=True, load_to_ram=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.train = train\n",
    "        self.load_to_ram = load_to_ram\n",
    "        self.transform = transform\n",
    "        self.to_tensor = T.ToTensor()\n",
    "        self.all_files = []\n",
    "        self.all_labels = []\n",
    "        self.images = []\n",
    "\n",
    "        self.filenames = os.listdir(self.folder)\n",
    "        self.train_val_labels = pd.read_csv('bhw1-dataset/labels.csv')\n",
    "        train_files, val_files = train_test_split(self.filenames, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "        if train:\n",
    "            self.all_files += train_files\n",
    "            self.all_labels += list(self.train_val_labels.loc[self.train_val_labels['Id'].isin(train_files), 'Label'].values)\n",
    "            if load_to_ram:\n",
    "                self.images += self._load_images(train_files)\n",
    "        else:\n",
    "            self.all_files += val_files\n",
    "            self.all_labels += list(self.train_val_labels.loc[self.train_val_labels['Id'].isin(val_files), 'Label'].values)\n",
    "            if load_to_ram:\n",
    "                self.images += self._load_images(val_files)\n",
    "\n",
    "\n",
    "    def _load_images(self, files):\n",
    "        images = []\n",
    "        for filename in tqdm(files, 'Dataset loading'):\n",
    "            image = Image.open(os.path.join(self.folder, filename)).convert('RGB')\n",
    "            images += [image]\n",
    "        return images\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.all_labels[index]\n",
    "        if self.load_to_ram:\n",
    "            image = self.images[index]\n",
    "        else:\n",
    "            filename = self.all_files[index]\n",
    "            image = Image.open(os.path.join(self.folder, filename))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_folder = 'bhw1-dataset/trainval/'\n",
    "train_dataset = BWHDataset(folder=train_val_folder, train=True, load_to_ram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, (64, 64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_image, temp_label = train_dataset[100]\n",
    "temp_label, temp_image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset loading: 100%|██████████| 50000/50000 [11:07<00:00, 74.89it/s] \n",
      "Dataset loading: 100%|██████████| 50000/50000 [10:56<00:00, 76.17it/s] \n"
     ]
    }
   ],
   "source": [
    "train_dataset = BWHDataset(folder=train_val_folder, train=True, load_to_ram=True, transform=test_transform)\n",
    "test_dataset = BWHDataset(folder=train_val_folder, train=False, load_to_ram=True, transform=test_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_loader):\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    model.train()\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        acc = (logits.argmax(dim=1) == target).sum() / data.shape[0]\n",
    "        acc_log.append(acc.item()) \n",
    "\n",
    "    return loss_log, acc_log\n",
    "\n",
    "\n",
    "# @torch.inference_mode()\n",
    "def test(model, criterion, loader):\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    model.eval()\n",
    "    \n",
    "    for data, target in tqdm(loader, 'Test batch'):     \n",
    "        data = data.to(device)\n",
    "        target = torch.from_numpy(target.reshape(1, -1)[0]).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(data.unsqueeze(0))\n",
    "            loss = criterion(logits, target)\n",
    "        \n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        acc = (logits.argmax(dim=1) == target).sum()  / data.shape[0]\n",
    "        acc_log.append(acc.item()) \n",
    "    \n",
    "    return np.mean(loss_log), np.mean(acc_log)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, train_loader):\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    model.train()\n",
    "\n",
    "    for data, target in tqdm(train_loader, 'Train batch'):\n",
    "        data = data.to(device)\n",
    "        target = torch.from_numpy(target.reshape(1, -1)[0]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data.unsqueeze(0))\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        acc = (logits.argmax(dim=1) == target).sum() / data.shape[0]\n",
    "        acc_log.append(acc.item()) \n",
    "\n",
    "    return loss_log, acc_log\n",
    "\n",
    "def train(model, optimizer, criterion, n_epochs, train_loader, val_loader, scheduler=None):\n",
    "    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        val_loss, val_acc = test(model, criterion, val_loader)\n",
    "        \n",
    "        train_loss_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "        \n",
    "        val_loss_log.append(val_loss)\n",
    "        val_acc_log.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\" train loss: {np.mean(train_loss):.5f}, train acc: {np.mean(train_acc):.5f}\")\n",
    "        print(f\" val loss: {val_loss:.5f}, val acc: {val_acc:.5f}\\n\")\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_small\n",
    "\n",
    "num_epochs = 20\n",
    "n_classes = train_dataset.train_val_labels['Label'].unique().size\n",
    "model = mobilenet_v3_small(num_classes=n_classes).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " train loss: 5.33216, train acc: 0.00163\n",
      " val loss: 5.70516, val acc: 0.00176\n",
      "\n",
      "Epoch 1\n",
      " train loss: 5.32890, train acc: 0.00173\n",
      " val loss: 6.05525, val acc: 0.00165\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[39m=\u001b[39m train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)\n",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, n_epochs, train_loader, val_loader, scheduler)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[39m=\u001b[39m [], [], [], []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_epoch(model, optimizer, criterion, train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m test(model, criterion, val_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     train_loss_log\u001b[39m.\u001b[39mextend(train_loss)\n",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m logits \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, target)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#X15sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss_log\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# one epoch ~100 min :(\n",
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimaz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to C:\\Users\\dimaz/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_small-047dcff4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975482316548478bafed0d11ceb82d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/9.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.models import MobileNet_V3_Small_Weights\n",
    "\n",
    "model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[3] = torch.nn.Linear(1024, n_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my pc is too weak, i'm sorry :(\n",
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сокращение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice_param = 0.3\n",
    "# grouped_labels = train_val_labels.groupby('Label')['Id'].apply(np.array)\n",
    "# cut_labels = grouped_labels.apply(lambda x: np.random.choice(x, size=np.floor(x.size * choice_param).astype(int)))\n",
    "# splitted_labels = cut_labels.apply(lambda x: train_test_split(x, test_size=TEST_SIZE))\n",
    "# train_data, val_data = [], []\n",
    "# for label_data in splitted_labels:\n",
    "#     train_data.extend(label_data[0])\n",
    "#     val_data.extend(label_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "TEST_SIZE = 0.3\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# fixed dataset loader\n",
    "class BWHDataset(Dataset):\n",
    "    SPLIT_RANDOM_SEED = RANDOM_STATE\n",
    "    SPLIT_TEST_SIZE = TEST_SIZE\n",
    "\n",
    "    def __init__(self, folder='bhw1-dataset/trainval/', choice_param=None, n_classes=None, train=True, load_to_ram=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.train = train\n",
    "        self.load_to_ram = load_to_ram\n",
    "        self.transform = transform\n",
    "        self.to_tensor = T.ToTensor()\n",
    "        self.all_files = []\n",
    "        self.all_labels = []\n",
    "        self.images = []\n",
    "        self.choice_param = choice_param\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.filenames = os.listdir(self.folder)\n",
    "        self.train_val_labels = pd.read_csv('bhw1-dataset/labels.csv')        \n",
    "        self.grouped_labels = self.train_val_labels.groupby('Label')['Id'].apply(np.array)\n",
    "        if self.n_classes is not None:\n",
    "            self.grouped_labels = self.grouped_labels[:self.n_classes]\n",
    "        if self.choice_param is not None:\n",
    "            self.grouped_labels = self.grouped_labels.apply(\n",
    "                lambda x: np.random.choice(x, size=np.floor(x.size * self.choice_param).astype(int))\n",
    "            )\n",
    "        splitted_labels = self.grouped_labels.apply(lambda x: train_test_split(x, test_size=TEST_SIZE, random_state=RANDOM_STATE))\n",
    "        train_files, val_files = [], []\n",
    "        for label_data in splitted_labels:\n",
    "            train_files.extend(label_data[0])\n",
    "            val_files.extend(label_data[1])\n",
    "        if train:\n",
    "            self.all_files += train_files\n",
    "            self.all_labels += list(self.train_val_labels.loc[self.train_val_labels['Id'].isin(train_files), 'Label'].values)\n",
    "            if load_to_ram:\n",
    "                self.images += self._load_images(train_files)\n",
    "        else:\n",
    "            self.all_files += val_files\n",
    "            self.all_labels += list(self.train_val_labels.loc[self.train_val_labels['Id'].isin(val_files), 'Label'].values)\n",
    "            if load_to_ram:\n",
    "                self.images += self._load_images(val_files)\n",
    "        \n",
    "                \n",
    "\n",
    "    def _load_images(self, files):\n",
    "        images = []\n",
    "        for filename in tqdm(files, 'Dataset loading'):\n",
    "            image = Image.open(os.path.join(self.folder, filename)).convert('RGB')\n",
    "            images += [image]\n",
    "        return images\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.all_files[index]\n",
    "        label = self.train_val_labels[self.train_val_labels['Id']==filename]['Label'].values[0]\n",
    "        if self.load_to_ram:\n",
    "            image = self.images[index]\n",
    "        else:\n",
    "            image = Image.open(os.path.join(self.folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset loading: 100%|██████████| 350/350 [00:00<00:00, 4647.75it/s]\n",
      "Dataset loading: 100%|██████████| 150/150 [00:01<00:00, 79.77it/s]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "train_dataset = BWHDataset(folder=train_val_folder, choice_param=0.1, n_classes=n_classes, train=True, load_to_ram=True, transform=test_transform)\n",
    "test_dataset = BWHDataset(folder=train_val_folder, choice_param=0.1, n_classes=n_classes, train=False, load_to_ram=True, transform=test_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка корректности датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[100][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainval_76106.jpg'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.all_files[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76106    2\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = train_dataset.train_val_labels\n",
    "df_temp[df_temp['Id']==train_dataset.all_files[100]]['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 'trainval_77878.jpg')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[100][1], test_dataset.all_files[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77878    6\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = test_dataset.train_val_labels\n",
    "df_temp[df_temp['Id']==test_dataset.all_files[100]]['Label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import MobileNet_V3_Small_Weights\n",
    "\n",
    "model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[3] = torch.nn.Linear(1024, n_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:20<00:00,  4.34it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:03<00:00, 42.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " train loss: 3.38053, train acc: 0.30286\n",
      " val loss: 15.67615, val acc: 0.02889\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:32<00:00, 10.90it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:04<00:00, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " train loss: 4.23934, train acc: 0.30381\n",
      " val loss: 343.20961, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:36<00:00,  9.63it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:07<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      " train loss: 4.34544, train acc: 0.29524\n",
      " val loss: 629.28765, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:31<00:00,  3.84it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:09<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      " train loss: 5.76101, train acc: 0.28857\n",
      " val loss: 22.39320, val acc: 0.03556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:02<00:00,  5.59it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:09<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      " train loss: 2.76583, train acc: 0.29238\n",
      " val loss: 504.64850, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:26<00:00,  4.03it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:09<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      " train loss: 2.97904, train acc: 0.28952\n",
      " val loss: 260.12550, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:56<00:00,  6.17it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:03<00:00, 39.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      " train loss: 1.92575, train acc: 0.29048\n",
      " val loss: 569.96495, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:11<00:00,  4.89it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:09<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      " train loss: 2.09853, train acc: 0.27810\n",
      " val loss: 514.20815, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:24<00:00,  4.14it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:03<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      " train loss: 1.50990, train acc: 0.26286\n",
      " val loss: 570.03051, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:37<00:00,  9.42it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:05<00:00, 27.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      " train loss: 1.82238, train acc: 0.23619\n",
      " val loss: 580.20277, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:08<00:00,  5.10it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:03<00:00, 40.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      " train loss: 1.87407, train acc: 0.22952\n",
      " val loss: 496.84301, val acc: 0.02667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:16<00:00,  4.56it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:12<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      " train loss: 1.78497, train acc: 0.19238\n",
      " val loss: 532.07928, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:19<00:00,  4.42it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:09<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      " train loss: 2.10213, train acc: 0.13429\n",
      " val loss: 491.34201, val acc: 0.03111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:05<00:00,  5.34it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:04<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      " train loss: 1.85107, train acc: 0.16952\n",
      " val loss: 518.02770, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [01:04<00:00,  5.42it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:09<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      " train loss: 2.28086, train acc: 0.06381\n",
      " val loss: 531.56555, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:54<00:00,  6.48it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:04<00:00, 32.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      " train loss: 2.67330, train acc: 0.00476\n",
      " val loss: 530.59560, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:37<00:00,  9.39it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:04<00:00, 36.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      " train loss: 2.48849, train acc: 0.00571\n",
      " val loss: 530.97504, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:34<00:00, 10.28it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:04<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      " train loss: 2.43242, train acc: 0.02095\n",
      " val loss: 531.20252, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:48<00:00,  7.16it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:03<00:00, 38.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      " train loss: 2.36846, train acc: 0.02000\n",
      " val loss: 531.44133, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 350/350 [00:36<00:00,  9.67it/s]\n",
      "Test batch: 100%|██████████| 150/150 [00:04<00:00, 32.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      " train loss: 2.34448, train acc: 0.02095\n",
      " val loss: 531.39281, val acc: 0.03333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сокращение датасета V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset loading: 100%|██████████| 1750/1750 [00:20<00:00, 84.15it/s] \n",
      "Dataset loading: 100%|██████████| 750/750 [00:09<00:00, 75.52it/s] \n"
     ]
    }
   ],
   "source": [
    "n_classes = 5\n",
    "train_dataset = BWHDataset(folder=train_val_folder, n_classes=n_classes, train=True, load_to_ram=True, transform=train_transform)\n",
    "test_dataset = BWHDataset(folder=train_val_folder, n_classes=n_classes, train=False, load_to_ram=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT).to(device)\n",
    "model.classifier[3] = torch.nn.Linear(1024, n_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [04:13<00:00,  6.90it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:18<00:00, 40.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " train loss: 0.18271, train acc: 0.33105\n",
      " val loss: 11.02816, val acc: 0.07378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [04:20<00:00,  6.71it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:32<00:00, 22.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " train loss: 0.46256, train acc: 0.33067\n",
      " val loss: 116.51251, val acc: 0.06667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [03:34<00:00,  8.15it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:25<00:00, 29.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      " train loss: 0.49168, train acc: 0.33086\n",
      " val loss: 722.96066, val acc: 0.06667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [03:31<00:00,  8.29it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:19<00:00, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      " train loss: 0.47645, train acc: 0.33067\n",
      " val loss: 340.16152, val acc: 0.06622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch:   4%|▎         | 65/1750 [00:06<02:53,  9.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[39m=\u001b[39m train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)\n",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 37\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, n_epochs, train_loader, val_loader, scheduler)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[39m=\u001b[39m [], [], [], []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_epoch(model, optimizer, criterion, train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m test(model, criterion, val_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     train_loss_log\u001b[39m.\u001b[39mextend(train_loss)\n",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 37\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m logits \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, target)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y123sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss_log\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom RESNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockNet(nn.Module):\n",
    "    def __init__(self, image_channels=3, out_channels=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(  # 3 x 64 x 64\n",
    "            in_channels=image_channels, out_channels=out_channels, kernel_size=1\n",
    "        ) # 64 x 64 x 64\n",
    "        self.basic_block = nn.Sequential( # 3 x 64 x 64\n",
    "            nn.Conv2d(in_channels=image_channels, out_channels=out_channels, kernel_size=3, padding=1), # 64 x 64 x 64\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1), # 64 x 64 x 64\n",
    "            nn.BatchNorm2d(num_features=out_channels) \n",
    "        ) # 64 x 64 x 64\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=5,stride=7) \n",
    "        self.linear = nn.Linear(in_features=64 * 9 * 9, out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.conv1(x) # 64 x 64 x 64\n",
    "        basic_out = self.basic_block(x) # 64 x 64 x 64\n",
    "        pooled_out = self.avgpool(self.relu(basic_out + residual)) # 64 x 4 x 4\n",
    "        out = self.linear(pooled_out.flatten(start_dim=1)) # 64 * 9 * 9\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BasicBlockNet()\n",
    "model = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [01:37<00:00, 17.98it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:10<00:00, 68.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " train loss: 0.71046, train acc: 0.32800\n",
      " val loss: 7.13116, val acc: 0.06667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [01:52<00:00, 15.62it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:14<00:00, 52.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " train loss: 0.32859, train acc: 0.31486\n",
      " val loss: 4.22846, val acc: 0.06667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [02:06<00:00, 13.78it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:22<00:00, 33.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      " train loss: 0.73043, train acc: 0.31429\n",
      " val loss: 4.18234, val acc: 0.06667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch: 100%|██████████| 1750/1750 [02:03<00:00, 14.17it/s]\n",
      "Test batch: 100%|██████████| 750/750 [00:16<00:00, 45.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      " train loss: 0.47531, train acc: 0.30819\n",
      " val loss: 119.60040, val acc: 0.06667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch:   9%|▉         | 160/1750 [00:10<01:43, 15.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[39m=\u001b[39m train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)\n",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 43\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, n_epochs, train_loader, val_loader, scheduler)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m train_loss_log, train_acc_log, val_loss_log, val_acc_log \u001b[39m=\u001b[39m [], [], [], []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_epoch(model, optimizer, criterion, train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m test(model, criterion, val_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     train_loss_log\u001b[39m.\u001b[39mextend(train_loss)\n",
      "\u001b[1;32md:\\ФТиАД\\NeuralNetworks\\intro-to-dl-hse\\homeworks-big\\bhw1\\bhw_01.ipynb Cell 43\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss_log\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m acc \u001b[39m=\u001b[39m (logits\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m target)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%D0%A4%D0%A2%D0%B8%D0%90%D0%94/NeuralNetworks/intro-to-dl-hse/homeworks-big/bhw1/bhw_01.ipynb#Y135sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m acc_log\u001b[39m.\u001b[39mappend(acc\u001b[39m.\u001b[39mitem()) \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, criterion, num_epochs, train_dataset, test_dataset, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570dd33043ea43a5929913ff205be499021c2ab8ef3bcad34e41dcd3206e6bcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
